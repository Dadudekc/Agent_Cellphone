[API]
# AlphaVantage API Key:
# This is your API key for AlphaVantage, which is used to fetch historical stock data.
AlphaVantage = YOUR_ALPHA_VANTAGE_API_KEY

# Polygon.io API Key:
# This is your API key for Polygon.io, which is used to fetch historical stock data.
PolygonIO = YOUR_POLYGON_IO_API_KEY

# NASDAQ API Key:
# This is your API key for the NASDAQ API, which is used to fetch historical stock data.
NASDAQ = YOUR_NASDAQ_API_KEY

# Directory path for saving fetched CSV data
[csv_directory]
# Directory Path:
# This is the directory where the fetched stock data in CSV format will be saved.
# You can specify the path to your desired directory here.
directory_path = Your_Default_CSV_Directory

# Path configurations for data_processing1.py and data_processing2.py
[Paths]
# Loading Path 1:
# This is the directory path where the script expects to find input CSV files to process for data_processing1.py
loading_path = Your_Loading_Path_For_Data_Processing_1

# Loading Path 2:
# This is the directory path where the script expects to find input CSV files to process for data_processing2.py
loading_path2 = Your_Loading_Path_For_Data_Processing_2

# Saving Path 2:
# This is the directory path where data_processing2.py will save processed/enriched CSV files.
saving_path2 = Your_Saving_Path_For_Data_Processing_2

# Paths section specifies the folders where your data and models are stored.
# Update these paths to match the locations of your data and models.
data_folder = path/to/your/data/folder  # Path to the folder containing your data CSV files
models_directory = path/to/your/models/folder  # Path to the folder where trained models will be saved

# Model section contains configuration related to your machine learning model.
# The target_column should be set to the name of the column in your CSV files that represents the target variable.
[Model]
target_column = close  # Update this to match your target variable column name

# Training section contains configuration related to model training.
# test_size specifies the proportion of data to be used for testing (typically a float between 0 and 1).
# scaler_type specifies the type of data scaling to be applied during preprocessing (e.g., standard, minmax, etc.).
[Training]
test_size = 0.2  # Proportion of data to be used for testing (e.g., 0.2 for 20%)
scaler_type = standard  # Type of data scaling (options: standard, minmax, robust, quantile, power, normalizer, maxabs)
